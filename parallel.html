<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>imager in parallel</title>

<script src="parallel_files/header-attrs-2.14/header-attrs.js"></script>
<script src="parallel_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="parallel_files/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="parallel_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="parallel_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="parallel_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="parallel_files/navigation-1.1/tabsets.js"></script>
<link href="parallel_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="parallel_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div id="header">



<h1 class="title toc-ignore">imager in parallel</h1>

</div>

<div id="TOC">
<ul>
<li><a href="#parallelising-from-r" id="toc-parallelising-from-r"><span
class="toc-section-number">1</span> Parallelising from R</a></li>
<li><a href="#native-parallelisation-cimg-and-openmp"
id="toc-native-parallelisation-cimg-and-openmp"><span
class="toc-section-number">2</span> Native parallelisation: CImg and
OpenMP</a></li>
<li><a href="#parallelisation-in-r-vs.-native-parallelisation"
id="toc-parallelisation-in-r-vs.-native-parallelisation"><span
class="toc-section-number">3</span> Parallelisation in R vs. native
parallelisation</a></li>
</ul>
</div>

<p><a href="http://sites.google.com/site/simonbarthelme">Simon
Barthelmé</a> (GIPSA-lab, CNRS)</p>
<p>There are several ways of doing things in parallel with imager. One
of them is to use of R’s many packages for doing things in parallel
(parallel, futures, etc.). The other one is to take advantage of CImg’s
ative use of OpenMP.</p>
<div id="parallelising-from-r" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Parallelising from
R</h1>
<p>Parallelising from R is very easy (provided that what you want to do
actually parallelises). Something that does parallelise easily is to run
the same operations on different images, or on different image
channels.</p>
<pre class="r"><code>library(imager)</code></pre>
<pre><code>## Loading required package: magrittr</code></pre>
<pre><code>## 
## Attaching package: &#39;imager&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:magrittr&#39;:
## 
##     add</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     convolve, spectrum</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     frame</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     save.image</code></pre>
<pre class="r"><code>library(parallel)

#A really big image
im &lt;- boats %&gt;% imresize(8)
#Rank pixels in each image channel 
#Serial version 
fun &lt;- function() imsplit(im,&quot;c&quot;) %&gt;% lapply(rank)
    
system.time(fun())</code></pre>
<pre><code>##    user  system elapsed 
##   8.004   0.219   8.230</code></pre>
<pre class="r"><code>#Parallel version: use mclapply
fun.par &lt;- function() imsplit(im,&quot;c&quot;) %&gt;% mclapply(rank,mc.cores=2)
system.time(fun.par())</code></pre>
<pre><code>##    user  system elapsed 
##   2.800   0.369   5.955</code></pre>
</div>
<div id="native-parallelisation-cimg-and-openmp" class="section level1"
number="2">
<h1><span class="header-section-number">2</span> Native parallelisation:
CImg and OpenMP</h1>
<p>Many CImg operations are parallelised natively. The parallelisation
is optional and is only activated starting from a certain image size.
The speed-ups are sublinear, meaning that unless your image is gigantic
you won’t gain much from throwing 200 cores at a problem.</p>
<p>By default OpenMP will grab all the CPU cores it can. To correctly
use multiple threads users should set nthreads in cimg.use.openmp. You
also need to be careful that this is not higher than the value in the
system environment variable OMP_THREAD_LIMIT (this can be checked with
Sys.getenv(‘OMP_THREAD_LIMIT’)). The OMP_THREAD_LIMIT thread limit
usually needs to be correctly set before launching R, so using
Sys.setenv once a session has started is not certain to work.</p>
<pre class="r"><code>library(imager)
library(microbenchmark)
#Let&#39;s do a big convolution
a &lt;- boats
b &lt;- imnoise(30,30) 
fun &lt;- function() convolve(a,b)
#No parallelisation
cimg.use.openmp(nthreads = 1)</code></pre>
<pre><code>## NULL</code></pre>
<pre class="r"><code>microbenchmark(fun(),times=15)</code></pre>
<pre><code>## Unit: milliseconds
##   expr      min       lq     mean   median       uq      max neval
##  fun() 758.5587 770.5574 793.5305 783.0165 816.8524 843.8794    15</code></pre>
<pre class="r"><code>#2 cores
cimg.use.openmp(nthreads = 2)</code></pre>
<pre><code>## NULL</code></pre>
<pre class="r"><code>microbenchmark(fun(),times=15)</code></pre>
<pre><code>## Unit: milliseconds
##   expr      min      lq     mean   median       uq      max neval
##  fun() 388.7225 395.259 403.4662 400.2312 405.8684 444.1365    15</code></pre>
<pre class="r"><code>#4 cores, etc.
cimg.use.openmp(nthreads = 4)</code></pre>
<pre><code>## NULL</code></pre>
<pre class="r"><code>microbenchmark(fun(),times=15)</code></pre>
<pre><code>## Unit: milliseconds
##   expr      min       lq     mean   median      uq      max neval
##  fun() 199.6942 202.2179 205.0651 204.1085 206.369 217.8173    15</code></pre>
<p>If CImg’s parallelisation doesn’t seem to work on your machine, it’s
probably because you compiled the package with Clang, which has patchy
support for OpenMP. Recompile using gcc if possible. For macOS check
here: <a href="https://mac.r-project.org/openmp/"
class="uri">https://mac.r-project.org/openmp/</a></p>
</div>
<div id="parallelisation-in-r-vs.-native-parallelisation"
class="section level1" number="3">
<h1><span class="header-section-number">3</span> Parallelisation in R
vs. native parallelisation</h1>
<p>Here’s a simple benchmark: medianblur can be parallelised across
image channels. First, the R version using mclapply:</p>
<pre class="r"><code>cimg.use.openmp(nthreads = 1)</code></pre>
<pre><code>## NULL</code></pre>
<pre class="r"><code>fun.R &lt;- function() imsplit(boats,&quot;c&quot;) %&gt;% mclapply(function(v) medianblur(v,50),mc.cores=3)
microbenchmark(fun.R(),times=20)</code></pre>
<pre><code>## Unit: seconds
##     expr      min       lq     mean  median       uq      max neval
##  fun.R() 2.522276 2.573416 2.676955 2.65224 2.783309 2.861924    20</code></pre>
<p>Second, CImg’s native version:</p>
<pre class="r"><code>cimg.use.openmp(nthreads = 4)</code></pre>
<pre><code>## NULL</code></pre>
<pre class="r"><code>fun.nat &lt;- function() medianblur(boats,50)
microbenchmark(fun.nat(),times=20)</code></pre>
<pre><code>## Unit: seconds
##       expr      min       lq     mean  median       uq      max neval
##  fun.nat() 1.975586 1.980098 2.019698 2.00531 2.032463 2.142027    20</code></pre>
<p>Pros and cons of using native parallelisation:</p>
<ul>
<li>Transparent</li>
<li>Very efficient if you work on large images</li>
<li>Only works on compatible platforms (i.e., needs gcc)</li>
</ul>
<p>Pros and cons of parallelisation from R:</p>
<ul>
<li>More flexible (futures, multiple threads, etc.)</li>
<li>Effective if you run a long chain of operations over many
images</li>
<li>Better cross-platform support</li>
<li>Slightly less transparent and possibly slower</li>
</ul>
<p>Note that both types of parallelisation can be combined if you can
spread the load over several machines.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
